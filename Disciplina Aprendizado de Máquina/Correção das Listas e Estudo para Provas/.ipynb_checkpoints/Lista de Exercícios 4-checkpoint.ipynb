{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de Exercícios 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM LIBRARY\n",
    "def standardize(X):\n",
    "    X_std = np.copy(X)\n",
    "    n_cols = X.shape[1]\n",
    "    for i in range(n_cols):\n",
    "        X_std[:, i] = (X[:, i] - np.mean(X[:, i])) / np.std(X[:, i])\n",
    "    return X_std\n",
    "\n",
    "def normalize(X):\n",
    "    X_norm = np.copy(X)\n",
    "    n_cols = X.shape[1]\n",
    "    for i in range(n_cols):\n",
    "        X_norm[:, i] = (X[:, i] - np.min(X[:, i])) / (np.max(X[:, i]) - np.min(X[:, i]))\n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESAMPLE LIBRARY\n",
    "def split_k_fold(n_elem, n_splits=3, shuffle=True, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if(n_splits < 3):\n",
    "        return \"Valor de n_splits deve ser maior que 2\"\n",
    "    \n",
    "    a = [i for i in range(n_elem)]\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(a)\n",
    "    \n",
    "    splits_size = int(n_elem/n_splits)\n",
    "    idx_train = list()\n",
    "    idx_test = list()\n",
    "    x = 0\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        a_copy = list(a)\n",
    "        fold = list()\n",
    "        while len(fold) < splits_size:\n",
    "            b = a_copy[x]\n",
    "            fold.append(b)\n",
    "            x = x+1\n",
    "        idx_test.append(fold)\n",
    "        for k in range (len(fold)):\n",
    "            a_copy.remove(fold[k])\n",
    "        idx_train.append(a_copy)\n",
    "        \n",
    "    return idx_train, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset[:,:11]\n",
    "y = dataset[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elem = len(X)\n",
    "idx_train, idx_test = split_k_fold(n_elem,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent: 0.429752420124\n"
     ]
    }
   ],
   "source": [
    "#SGD - Stochastic Gradient Descent\n",
    "sgd_model = linear_model.SGDRegressor()\n",
    "soma_sgd = 0\n",
    "for i in range(5):\n",
    "    std_scale = StandardScaler().fit(X[idx_train[i]])\n",
    "    X_train_std = std_scale.transform(X[idx_train[i]])\n",
    "    X_test_std = std_scale.transform(X[idx_test[i]])\n",
    "    sgd_model.fit(X_train_std, y[idx_train[i]])\n",
    "    y_pred = sgd_model.predict(X_test_std)\n",
    "    soma_sgd =  soma_sgd + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('Stochastic Gradient Descent:', soma_sgd/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model: 0.428092382161\n"
     ]
    }
   ],
   "source": [
    "#Linear Model\n",
    "lr_model = linear_model.LinearRegression()\n",
    "soma_lr = 0\n",
    "for i in range(5):\n",
    "    lr_model.fit(X[idx_train[i]], y[idx_train[i]])\n",
    "    y_pred = lr_model.predict(X[idx_test[i]])\n",
    "    soma_lr =  soma_lr + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('Linear Model:', soma_lr/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVR: 0.974792804696\n"
     ]
    }
   ],
   "source": [
    "#Linear SVR\n",
    "lsvr_model = svm.LinearSVR()\n",
    "soma_lsvr = 0\n",
    "for i in range(5):\n",
    "    lsvr_model.fit(X[idx_train[i]], y[idx_train[i]])\n",
    "    y_pred = lsvr_model.predict(X[idx_test[i]])\n",
    "    soma_lsvr =  soma_lsvr + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('Linear SVR:', soma_lsvr/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR: 0.483420047196\n"
     ]
    }
   ],
   "source": [
    "#SVR\n",
    "svr_model = svm.SVR()\n",
    "soma_svr = 0\n",
    "for i in range(5):\n",
    "    svr_model.fit(X[idx_train[i]], y[idx_train[i]])\n",
    "    y_pred = svr_model.predict(X[idx_test[i]])\n",
    "    soma_svr =  soma_svr + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('SVR:', soma_svr/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor: 0.365222570533\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "rfr_model = ensemble.RandomForestRegressor()\n",
    "soma_rfr = 0\n",
    "for i in range(5):\n",
    "    rfr_model.fit(X[idx_train[i]], y[idx_train[i]])\n",
    "    y_pred = rfr_model.predict(X[idx_test[i]])\n",
    "    soma_rfr =  soma_rfr + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('Random Forest Regressor:', soma_rfr/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor: 0.384073992634\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gbr_model = ensemble.GradientBoostingRegressor()\n",
    "soma_gbr = 0\n",
    "for i in range(5):\n",
    "    gbr_model.fit(X[idx_train[i]], y[idx_train[i]])\n",
    "    y_pred = gbr_model.predict(X[idx_test[i]])\n",
    "    soma_gbr =  soma_gbr + metrics.mean_squared_error(y[idx_test[i]], y_pred)\n",
    "print('Gradient Boosting Regressor:', soma_gbr/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfico com a Média dos MSE dos modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nckkqzpBLUnGGXJKKM+SSVJwhl6Ti/h/lNvOPyBCfPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fabf9ad320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['SGD','LR','LSVR','SVR','RFR','GBR']\n",
    "class_ = [(soma_sgd/5), (soma_lr/5), (soma_lsvr/5), (soma_svr/5), (soma_rfr/5), (soma_gbr/5)]\n",
    "plt.grid()\n",
    "plt.bar(range(len(class_names)),class_)\n",
    "plt.xticks(range(len(class_names)), class_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Final - Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = ensemble.RandomForestRegressor()\n",
    "final_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
